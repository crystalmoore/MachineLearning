{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\WorkSoftWare\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download the mnist to the path '~/.keras/datasets/' if it is the first time to be called\n",
    "# training X shape (60000, 28x28), Y shape (60000, ). test X shape (10000, 28x28), Y shape (10000, )\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data pre-processing\n",
    "X_train = X_train.reshape(-1, 1,28, 28)/255.\n",
    "X_test = X_test.reshape(-1, 1,28, 28)/255.\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 28, 28)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Another way to build your CNN\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\WorkSoftWare\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(filters=32, strides=1, padding=\"same\", input_shape=(1, 28, 28..., kernel_size=(5, 5))`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# Conv layer 1 output shape (32, 28, 28)\n",
    "model.add(Convolution2D(\n",
    "    # 32个滤波器会生成32张图片\n",
    "    filters=32,\n",
    "    nb_row=5,\n",
    "    nb_col=5,\n",
    "    strides=1,\n",
    "    padding='same',     # Padding method\n",
    "    input_shape=(1,      # channels\n",
    "                 28,28),   # height & width\n",
    "))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\WorkSoftWare\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\")`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Pooling layer 1 (max pooling) output shape(32,14,14)\n",
    "model.add(MaxPooling2D(\n",
    "    pool_size=(2, 2),\n",
    "    strides=(2, 2),\n",
    "    border_mode='same', #padding method\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\WorkSoftWare\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), padding=\"same\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Conv layer 2 output shape (64,14,14)\n",
    "model.add(Convolution2D(64,5,5,border_mode='same'))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\WorkSoftWare\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), padding=\"same\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Conv layer 2 output shape (64,7,7)\n",
    "model.add(MaxPooling2D(pool_size=(2,2),border_mode='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fully connected layer 1 input shape(64*7*7) = (3136), output shape (1024)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fully connected layer 2 to shape (10) for 10 classes\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Another way to define your optimizer\n",
    "adam = Adam(lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We add metrics to get more results you want to see\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training------------------------\n",
      "Epoch 1/2\n",
      "  320/60000 [..............................] - ETA: 37s - loss: 0.1810 - acc: 0.9406"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\WorkSoftWare\\Anaconda\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 36s 606us/step - loss: 0.1496 - acc: 0.9541\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 36s 598us/step - loss: 0.1099 - acc: 0.9664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a34283a908>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training------------------------')\n",
    "#Another way to train the model\n",
    "model.fit(X_train, y_train, nb_epoch=2, batch_size=32,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing------------------------\n",
      "10000/10000 [==============================] - 2s 175us/step\n"
     ]
    }
   ],
   "source": [
    "print('Testing------------------------')\n",
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test loss:  0.11193081341311335\n",
      "\n",
      " test accuracy:  0.965\n"
     ]
    }
   ],
   "source": [
    "print('\\n test loss: ',loss)\n",
    "print('\\n test accuracy: ',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 另一个训练表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data pre-processing\n",
    "X_train = X_train.reshape(-1, 1,28, 28)/255.\n",
    "X_test = X_test.reshape(-1, 1,28, 28)/255.\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Another way to build your CNN\n",
    "model = Sequential()\n",
    "# Conv layer 1 output shape (32, 28, 28)\n",
    "model.add(Convolution2D(\n",
    "    batch_input_shape=(None, 1, 28, 28),\n",
    "    # filters：卷积核的数目（即输出的维度）\n",
    "    filters=32,\n",
    "    # kernel_size：整数或由单个整数构成的list/tuple，卷积核的空域或时域窗长度\n",
    "    kernel_size=5,\n",
    "    # strides：整数或由单个整数构成的list/tuple，为卷积的步长。\n",
    "    strides=1,\n",
    "    padding='same',     # Padding method\n",
    "    # “channels_first”或“channels_last”之一，代表图像的通道维的位置。\n",
    "    # “channels_first”应将数据组织为（3,128,128）\n",
    "    # “channels_last”应将数据组织为（128,128,3）\n",
    "    data_format='channels_first',\n",
    "))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(\n",
    "    # pool_size：整数或长为2的整数tuple，代表在两个方向（竖直，水平）上的下采样因子，如取（2，2）将使图片在两个维度上均变为原长的一半。\n",
    "    pool_size=2,\n",
    "    # strides：整数或长为2的整数tuple，或者None，步长值。\n",
    "    strides=2,\n",
    "    padding='same',    # Padding method\n",
    "    data_format='channels_first',\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Conv layer 2 output shape (64, 14, 14)\n",
    "model.add(Convolution2D(\n",
    "    64, \n",
    "    5, \n",
    "    strides=1, \n",
    "    padding='same', \n",
    "    data_format='channels_first'))\n",
    "model.add(Activation('relu'))\n",
    "# Pooling layer 2 (max pooling) output shape (64, 7, 7)\n",
    "model.add(MaxPooling2D(\n",
    "    2, \n",
    "    2, \n",
    "    'same', \n",
    "    data_format='channels_first'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fully connected layer 1 input shape (64 * 7 * 7) = (3136), output shape (1024)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fully connected layer 2 to shape (10) for 10 classes\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=1e-4)\n",
    "\n",
    "# We add metrics to get more results you want to see\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ------------\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.2751 - acc: 0.9249\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0747 - acc: 0.9779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a3417786a0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training ------------')\n",
    "# Another way to train the model\n",
    "model.fit(X_train, y_train, epochs=2, batch_size=64,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing ------------\n",
      "10000/10000 [==============================] - 14s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "print('\\nTesting ------------')\n",
    "# Evaluate the model with the metrics we defined earlier\n",
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test loss:  0.055627744713798166\n",
      "\n",
      "test accuracy:  0.9815\n"
     ]
    }
   ],
   "source": [
    "print('\\ntest loss: ', loss)\n",
    "print('\\ntest accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
